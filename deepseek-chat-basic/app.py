import streamlit as st
from ollama import Client
import os

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="DeepSeek Chat",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ–èŠå¤©å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
client = Client(host=OLLAMA_HOST)

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– DeepSeek Chat")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.markdown("## æ¨¡å‹é…ç½®")
    temperature = st.slider("Temperature", 0.0, 2.0, 0.7)
    
    if st.button("æ¸…ç©ºå¯¹è¯", type="primary"):
        st.session_state.messages = []
        st.rerun()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯´ç‚¹ä»€ä¹ˆå§..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # ä½¿ç”¨stream=Trueæ¥è·å–æµå¼å“åº”
        stream = client.chat(
            model='deepseek-r1:14b',
            messages=st.session_state.messages,
            stream=True,
            options={
                'temperature': temperature
            }
        )
        
        # é€å­—æ˜¾ç¤ºå›å¤
        for chunk in stream:
            if chunk.message and chunk.message.content:
                full_response += chunk.message.content
                message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    
    # ä¿å­˜AIå›å¤
    st.session_state.messages.append({"role": "assistant", "content": full_response}) 