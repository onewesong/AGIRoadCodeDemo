import streamlit as st
from ollama import Client
import os
from roles import ROLE_TEMPLATES
from styles import set_think_style

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="DeepSeek Chat",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åº”ç”¨æ ·å¼
set_think_style()

# åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
client = Client(host=OLLAMA_HOST)

# è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
@st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
def get_available_models():
    try:
        models = client.list()
        return [model['model'] for model in models['models']]
    except Exception as e:
        st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return ['deepseek-r1:14b']  # é»˜è®¤æ¨¡å‹

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– DeepSeek Chat")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.markdown("## æ¨¡å‹è®¾ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    available_models = get_available_models()
    selected_model = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=available_models,
        index=available_models.index('deepseek-r1:14b') if 'deepseek-r1:14b' in available_models else 0
    )
    
    st.markdown("## è§’è‰²é€‰æ‹©")
    
    # è§’è‰²é€‰æ‹©ä¸‹æ‹‰èœå•
    selected_role = st.selectbox(
        "é€‰æ‹©AIåŠ©æ‰‹çš„è§’è‰²",
        options=list(ROLE_TEMPLATES.keys()),
        format_func=lambda x: f"{ROLE_TEMPLATES[x]['icon']} {ROLE_TEMPLATES[x]['name']}"
    )
    
    # æ˜¾ç¤ºè§’è‰²ä»‹ç»
    role = ROLE_TEMPLATES[selected_role]
    st.markdown(f"""
    **å½“å‰è§’è‰²**: {role['icon']} {role['name']}  
    **ç®€ä»‹**: {role['description']}
    """)
    
    # å…¶ä»–é…ç½®
    temperature = st.slider("Temperature", 0.0, 2.0, 0.7)
    
    if st.button("æ¸…ç©ºå¯¹è¯", type="primary"):
        st.session_state.messages = [{
            "role": "system",
            "content": ROLE_TEMPLATES[selected_role]["prompt"]
        }]
        st.rerun()

# åˆå§‹åŒ–å¯¹è¯å†å²
if "messages" not in st.session_state or not st.session_state.messages:
    st.session_state.messages = [{
        "role": "system",
        "content": ROLE_TEMPLATES[selected_role]["prompt"]
    }]

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages[1:]:  # è·³è¿‡system prompt
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input("è¯´ç‚¹ä»€ä¹ˆå§..."):
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢è§’è‰²
    current_role = st.session_state.messages[0]["content"]
    if current_role != ROLE_TEMPLATES[selected_role]["prompt"]:
        st.session_state.messages = [{
            "role": "system",
            "content": ROLE_TEMPLATES[selected_role]["prompt"]
        }]
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # ä½¿ç”¨stream=Trueæ¥è·å–æµå¼å“åº”
            stream = client.chat(
                model=selected_model,  # ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹
                messages=st.session_state.messages,
                stream=True,
                options={
                    'temperature': temperature
                }
            )
            
            # é€å­—æ˜¾ç¤ºå›å¤ï¼Œæ”¯æŒæ€è€ƒè¿‡ç¨‹
            for chunk in stream:
                if chunk.message and chunk.message.content:
                    content = chunk.message.content
                    # ç‰¹æ®Šæ ‡è®°è½¬æ¢
                    if content == "<think>":
                        content = "```think\n"
                    elif content == "</think>":
                        content = "\n```"
                    full_response += content
                    # å®æ—¶æ˜¾ç¤º
                    message_placeholder.markdown(full_response + "â–Œ")
            
            # æœ€ç»ˆæ˜¾ç¤º
            message_placeholder.markdown(full_response)
            
        except Exception as e:
            error_message = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
            message_placeholder.error(error_message)
            full_response = error_message
    
    # ä¿å­˜AIå›å¤
    st.session_state.messages.append({"role": "assistant", "content": full_response}) 